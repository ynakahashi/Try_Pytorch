{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/nn116003/torchtext-tutorial/blob/master/%E8%87%AA%E5%88%86%E3%81%AE%E3%83%87%E3%83%BC%E3%82%BF%E3%81%A7%E3%82%B5%E3%82%AF%E3%83%83%E3%81%A8attention%E3%81%A4%E3%81%8D%E6%96%87%E6%9B%B8%E5%88%86%E9%A1%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%82%92%E3%81%9F%E3%82%81%E3%81%99.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import janome\n",
    "from janome.tokenizer import Tokenizer\n",
    "\n",
    "import torchtext\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import FastText\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_t = Tokenizer()\n",
    "def tokenizer(text): \n",
    "    return [tok for tok in j_t.tokenize(text, wakati=True)]\n",
    "\n",
    "TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True, include_lengths=True, batch_first=True)\n",
    "LABEL = data.Field(sequential=False, use_vocab=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
